getwd()
setwd(getwd())
# load initial dataset
dataset <- read.csv("Final Dataset_LimitedCountries_first_sales.csv")
# remove all CLIPS from dataset (they add too many outliers)
dataset = subset(dataset, SalesType != 'CLIPS')
# drop BusinessArea and SalesType columns (dummy variable for them already exists - SalesType_Clips is not required)
dataset <- dataset[, !(names(dataset) %in% c('BusinessArea', 'SalesType', 'SalesType_CLIPS'))]
# add column TotalLengthOfContent to dataset
dataset$TotalLengthOfContent <- with(dataset, EpisodeLengthmin*TotalNumberOfEpisodes)
# add column AgeOfContent to dataset
dataset$AgeOfContent <- with(dataset, as.Date(DateOfDeal,"%m/%d/%Y")-as.Date(DateOfPremier,"%m/%d/%Y"))
View(dataset)
genome_data <- unique(dataset[,c(1, 9:77, 84:85)])
View(genome_data)
genome_data$Total_Revenue <- apply(genome_data, 1, function(x) sum(dataset[dataset$TitleId==x[1], ]$Revenue) )
View(genome_data)
dataset[dataset$TitleId==x[1], ]$Revenue
dataset[dataset$TitleId==genome_data[1], ]$Revenue
dataset[dataset$TitleId==genome_data[2], ]$Revenue
genome_data[1]
head(genome_data[1])
datasets_country <- split(dataset, f=dataset$final_country)
datasets_country
head(datasets_country)
size(datasets_country)
length(datasets_country)
for(country in datasets_country)
{ country[, c(18:25)] <- apply(country[, c(18:25)], 2, scale, center=TRUE, scale=TRUE) }
datasets_country[1]
datasets_country[1]$AUSTRALIA
datasets_country[1][1:2]
datasets_country[1][1]
datasets_country[1]$AUSTRALIA[1]
head(datasets_country[1]$AUSTRALIA[3])
head(datasets_country[1]$AUSTRALIA[4])
genome_data$Total_Revenue <- apply(genome_data, 1, function(x) sum(dataset[dataset$TitleId==x[1], ]$Revenue) )
View(genome_data)
# normalization functions
normalize_log2 <- function(x) { ifelse(abs(x) <= 1, 0, sign(x)*log2(abs(x))) }
normalize_0to1 <- function(x) { (x - min(x)) / (max(x) - min(x)) }
normalize_1to1 <- function(x) { -1 + (((x - min(x)) / (max(x) - min(x))) * 2) }
dataset_baseline <- unique(dataset[, c(1,18:49,53:79,81:86)])
dataset[, c(1,18:49,53:79,81:86)]
dataset[, c(1)]
head(dataset[, c(1)])
head(dataset[, c(1,18:49,53:79,81:86)])
head(dataset[, c(18:49)])
head(dataset[, c(16:49)])
head(dataset[, c(1,16:49,53:79,81:86)])
head(dataset[, c(53:79)])
head(dataset[, c(16:47)])
head(dataset[, c(51:79)])
setwd(getwd())
dataset <- read.csv("Final Dataset_LimitedCountries_first_sales.csv")
View(dataset)
dataset = subset(dataset, SalesType != 'CLIPS')
dataset <- dataset[, !(names(dataset) %in% c('BusinessArea', 'SalesType', 'SalesType_CLIPS'))]
dataset$TotalLengthOfContent <- with(dataset, EpisodeLengthmin*TotalNumberOfEpisodes)
dataset$AgeOfContent <- with(dataset, as.Date(DateOfDeal,"%m/%d/%Y")-as.Date(DateOfPremier,"%m/%d/%Y"))
View(dataset)
genome_data <- unique(dataset[,c(1, 9:77, 84:85)])
genome_data$Total_Revenue <- apply(genome_data, 1, function(x) sum(dataset[dataset$TitleId==x[1], ]$Revenue) )
# extract datasets by country from dataset
datasets_country <- split(dataset, f=dataset$final_country)
# normalize sentiment columns of each country by Z-score (calms2d to happy2d)
for(country in datasets_country)
{ country[, c(18:25)] <- apply(country[, c(16:23)], 2, scale, center=TRUE, scale=TRUE) }
# normalization functions
normalize_log2 <- function(x) { ifelse(abs(x) <= 1, 0, sign(x)*log2(abs(x))) }
normalize_0to1 <- function(x) { (x - min(x)) / (max(x) - min(x)) }
normalize_1to1 <- function(x) { -1 + (((x - min(x)) / (max(x) - min(x))) * 2) }
dataset_baseline <- unique(dataset[, c(1,16:47,51:77,79:85)])
View(dataset_baseline)
# load initial dataset
dataset     <- read.csv("Final Dataset_LimitedCountries_first_sales.csv")
genome_data <- unique(dataset[,c(1, 9:79)])
# add Total_Revenue column to genome data
getTotalRevenue <- function(x)
{
id <- x[1]
tempTable <- dataset[dataset$TitleId==id, ]
sum(tempTable$Revenue)
}
genome_data$Total_Revenue <- apply(genome_data, 1, getTotalRevenue)
# normalization functions
normalize_log2 <- function(x) { ifelse(abs(x) <= 1, 0, sign(x)*log2(abs(x))) }
normalize_0to1 <- function(x) { (x - min(x)) / (max(x) - min(x)) }
normalize_1to1 <- function(x) { -1 + (((x - min(x)) / (max(x) - min(x))) * 2) }
# create the baseline dataset for the baseline regression model
dataset_baseline <- unique(dataset[, c(1,18:49,53:79,81:86)])
View(dataset_baseline)
# load initial dataset
dataset <- read.csv("Final Dataset_LimitedCountries_first_sales.csv")
# remove all CLIPS from dataset (they add too many outliers)
dataset = subset(dataset, SalesType != 'CLIPS')
# drop BusinessArea and SalesType columns (dummy variable for them already exists - SalesType_Clips is not required)
dataset <- dataset[, !(names(dataset) %in% c('BusinessArea', 'SalesType', 'SalesType_CLIPS'))]
# add column TotalLengthOfContent to dataset
dataset$TotalLengthOfContent <- with(dataset, EpisodeLengthmin*TotalNumberOfEpisodes)
# add column AgeOfContent to dataset
dataset$AgeOfContent <- with(dataset, as.Date(DateOfDeal,"%m/%d/%Y")-as.Date(DateOfPremier,"%m/%d/%Y"))
# extract genome data from dataset into genome_data (brand name to toughtly_ad, length of content to age of content)
genome_data <- unique(dataset[,c(1, 9:77, 84:85)])
genome_data$Total_Revenue <- apply(genome_data, 1, function(x) sum(dataset[dataset$TitleId==x[1], ]$Revenue) )
# extract datasets by country from dataset
datasets_country <- split(dataset, f=dataset$final_country)
# normalize sentiment columns of each country by Z-score (calms2d to happy2d)
for(country in datasets_country)
{ country[, c(18:25)] <- apply(country[, c(16:23)], 2, scale, center=TRUE, scale=TRUE) }
# normalization functions
normalize_log2 <- function(x) { ifelse(abs(x) <= 1, 0, sign(x)*log2(abs(x))) }
normalize_0to1 <- function(x) { (x - min(x)) / (max(x) - min(x)) }
normalize_1to1 <- function(x) { -1 + (((x - min(x)) / (max(x) - min(x))) * 2) }
dataset_baseline <- unique(dataset[, c(1,16:47,51:77,79:85)])
View(dataset_baseline)
summary(dataset_baseline)
dataset_baseline[,c(65:67)] <- normalize_log2(dataset_baseline[,c(65:67)])
as.numeric(dataset_baseline$AgeOfContent)
dataset_baseline$AgeOfContent <- as.numeric(dataset_baseline$AgeOfContent)
summary(dataset_baseline)
dataset_baseline[,c(65:67)] <- normalize_log2(dataset_baseline[,c(65:67)])
View(dataset_baseline)
summary(dataset_baseline)
dataset_baseline <- unique(dataset[, c(1,16:47,51:77,79:85)])
dataset_baseline$AgeOfContent <- as.numeric(dataset_baseline$AgeOfContent)
dataset_baseline[,65] <- normalize_log2(dataset_baseline[,65])
dataset_baseline[,66] <- normalize_log2(dataset_baseline[,66])
dataset_baseline[,67] <- normalize_log2(dataset_baseline[,67])
View(dataset_baseline)
summary(dataset_baseline)
dataset_baseline[,c(3:4,6,8)] <- as.data.frame(lapply(dataset_baseline[,c(3:4,6,8)], normalize_0to1))
summary(dataset_baseline)
dataset_baseline[,c(2,5,7,9)] <- as.data.frame(lapply(dataset_baseline[,c(2,5,7,9)], normalize_1to1))
summary(dataset_baseline)
View(genome_data)

---
title:         Capstone Project
author:        Ainesh Pandey, Caroline Shi, Vaishnavi Vadlamani, Annamalai Kathirkamanathan
date created:  September 9, 2017
date modified: September 9, 2017
---

```{r echo=FALSE, warning=FALSE}
setwd("~/Desktop/Semester 3/Capstone/BBCcapstone")
```

```{r}

# Update - 9/27

# load initial dataset
dataset <- read.csv("Final Dataset_LimitedCountries_first_sales.csv")

# remove all CLIPS from dataset (they add too many outliers)
dataset = subset(dataset, SalesType != 'CLIPS')

# drop BusinessArea, SalesType columns,, Firstsale (dummy variable for them already exists - SalesType_Clips is not required)
dataset <- dataset[, !(names(dataset) %in% c('CustomerName', 'CustomerId', 'BusinessArea', 'SalesType', 'FirstSale', 'SalesType_CLIPS'))]

# add column TotalLengthOfContent to dataset
dataset$TotalLengthOfContent <- with(dataset, EpisodeLengthmin*TotalNumberOfEpisodes)

# add column AgeOfContent to dataset
dataset$AgeOfContent <- with(dataset, as.Date(DateOfDeal,"%m/%d/%Y")-as.Date(DateOfPremier,"%m/%d/%Y"))

# Change difftime to numeric
dataset$AgeOfContent <- as.numeric(dataset$AgeOfContent)

#To view the mapping of names to numerical values
#library(gdata)
#mapLevels(x=dataset$MediaType)

# Convert media type to numeric values
dataset$MediaType <- as.numeric(dataset$MediaType)

#Convert rating to numeric
dataset$Rated <- as.numeric(dataset$Rated)

# Drop date columns
genome_data <- dataset[, !(names(dataset) %in% c('DateOfDeal', 'DateOfPremier', 'EpisodeLengthmin', 'TotalNumberOfEpisodes'))]

# Reordering column Media type
index_mediatype <- grep("MediaType", names(genome_data))
genome_data <- genome_data[, c(1:2,4:5,index_mediatype,(6:ncol(genome_data)))]

# extract datasets by country from dataset
datasets_country <- split(genome_data, f=genome_data$final_country)

# Log normalization
normalize_log2 <- function(x) { ifelse(abs(x) <= 1, 0, sign(x)*log2(abs(x))) }


# normalize all numerical columns of each country by Z-score (media type, sequence # to age of content)
dataset_au <- as.data.frame(datasets_country$AUSTRALIA)
dataset_au[, c(7:16)] <- apply(dataset_au[, c(7:16)], 2, scale, center=TRUE, scale=TRUE)
dataset_au[, c(42:43)] <- apply(dataset_au[, c(42:43)], 2, scale, center=TRUE, scale=TRUE)
dataset_au[, c(77:78)] <- apply(dataset_au[, c(77:78)], 2, scale, center=TRUE, scale=TRUE)
dataset_au$Revenue <- normalize_log2(dataset_au$Revenue)
dataset_uk <- as.data.frame(datasets_country$`UNITED KINGDOM`)
dataset_uk[, c(7:16)] <- apply(dataset_uk[, c(7:16)], 2, scale, center=TRUE, scale=TRUE)
dataset_uk[, c(42:43)] <- apply(dataset_uk[, c(42:43)], 2, scale, center=TRUE, scale=TRUE)
dataset_uk[, c(77:78)] <- apply(dataset_uk[, c(77:78)], 2, scale, center=TRUE, scale=TRUE)
dataset_uk$Revenue <- normalize_log2(dataset_uk$Revenue)
dataset_fr <- as.data.frame(datasets_country$FRANCE)
dataset_fr[, c(7:16)] <- apply(dataset_fr[, c(7:16)], 2, scale, center=TRUE, scale=TRUE)
dataset_fr[, c(42:43)] <- apply(dataset_fr[, c(42:43)], 2, scale, center=TRUE, scale=TRUE)
dataset_fr[, c(77:78)] <- apply(dataset_fr[, c(77:78)], 2, scale, center=TRUE, scale=TRUE)
dataset_fr$Revenue <- normalize_log2(dataset_fr$Revenue)
dataset_usa <- as.data.frame(datasets_country$USA)
dataset_usa[, c(7:16)] <- apply(dataset_usa[, c(7:16)], 2, scale, center=TRUE, scale=TRUE)
dataset_usa[, c(42:43)] <- apply(dataset_usa[, c(42:43)], 2, scale, center=TRUE, scale=TRUE)
dataset_usa[, c(77:78)] <- apply(dataset_usa[, c(77:78)], 2, scale, center=TRUE, scale=TRUE)
dataset_usa$Revenue <- normalize_log2(dataset_usa$Revenue)

```


















































































```{r}

# Old

# load initial dataset
dataset <- read.csv("Final Dataset_LimitedCountries_first_sales.csv")

# remove all CLIPS from dataset (they add too many outliers)
dataset = subset(dataset, SalesType != 'CLIPS')

# drop BusinessArea and SalesType columns (dummy variable for them already exists)
dataset <- dataset[, !(names(dataset) %in% c('BusinessArea', 'SalesType', 'SalesType_CLIPS'))]

# add column TotalLengthOfContent to dataset
dataset$TotalLengthOfContent <- with(dataset, EpisodeLengthmin*TotalNumberOfEpisodes)

# add column AgeOfContent to dataset
dataset$AgeOfContent <- with(dataset, as.Date(DateOfDeal,"%m/%d/%Y")-as.Date(DateOfPremier,"%m/%d/%Y"))

# extract genome data from dataset into genome_data
genome_data <- unique(dataset[,c(1, 9:77, 84:85)])
genome_data$Total_Revenue <- apply(genome_data, 1, function(x) sum(dataset[dataset$TitleId==x[1], ]$Revenue) )

# extract datasets by country from dataset
datasets_country <- split(dataset, f=dataset$final_country)

# normalize sentiment columns of each country by Z-score
for(country in datasets_country)
{ country[, c(18:25)] <- apply(country[, c(18:25)], 2, scale, center=TRUE, scale=TRUE) }
```

```{r}
genome_data$Total_Revenue <- apply(genome_data, 1, function(x) sum(dataset[dataset$TitleId==x[1], ]$Revenue) )
```

```{r}
# normalization functions
normalize_log2 <- function(x) { ifelse(abs(x) <= 1, 0, sign(x)*log2(abs(x))) }
normalize_0to1 <- function(x) { (x - min(x)) / (max(x) - min(x)) }
normalize_1to1 <- function(x) { -1 + (((x - min(x)) / (max(x) - min(x))) * 2) }

# create the baseline dataset for the baseline regression model
dataset_baseline <- unique(dataset[, c(1,18:49,53:79,81:86)])
dataset_baseline[,66] <- normalize_log2(dataset_baseline[,66])
dataset_baseline[,c(3:4,6,8)] <- as.data.frame(lapply(dataset_baseline[,c(3:4,6,8)], normalize_0to1))
dataset_baseline[,c(2,5,7,9)] <- as.data.frame(lapply(dataset_baseline[,c(2,5,7,9)], normalize_1to1))

# generate the baseline regression model
baseline_model <- lm(Revenue ~ .-TitleId, data=dataset_baseline)
summary(baseline_model)
```


```{r}
datasets_country <- split(dataset, f=dataset$final_country)
print(datasets_country[1])
```
